
\section{Related Work}

%Prior art on design-space exploration of custom or domain-specific processors~\cite{Jordans2014,EusseSAMOS2014,Jozwiak2013} aims to find the optimal processor architecture in terms of area usage, power consumption and execution cycles. Processors with Single Instruction Multiple Data (SIMD) or Single Instruction Multiple Threads (SIMT) are typically used for data-flow or streaming applications. SIMD and SIMT architectures are not scalable due to a single Instruction Memory. Spatial architectures~\cite{7284058,8686088} helps to distribute the Instruction Memory and achieve a higher clock speed. State-of-the-art Spatial archiectures are designed for maximum flexibility and provide connections from any ALU or PE to any other using an interconnect. Prior art on using non-volatile memories as a replacement L2 memory perform co-simulation of the processor and the memory system and optimizes the cache replacement policies~\cite{4798259,7092595,6271803,7360193,200116,Patel2016ReducingSL,Komalan:2014,Mittal13f}.

%For the energy model~\cite{Yannan2019}

%Papers to cite for CDFG generation and Application Specific High LSynthesis~\cite{Coussy:2008:HSA:1457713,Kato2008}



Previous work on designing spatial processor focuses on the hardware architecture of the processor, while the optimization of the memory system is only partially taken into account.
In \cite{parashar2014efficient} a spatial processor with distributed control across PE using triggered instructions is presented. Their architecture is built around the guarded-action programming paradigm, where guards - boolean expressions specifying if an action is legal - are evaluated by a scheduler and trigger computations. Support for high level languages is missing, so this spatial processor needs to be programmed in a low level guarded-action language and the computation needs to be manually mapped on the PEs. Their memory system consist of two levels of memories (L1 and L2) and distributed scratch-pad memories located within the PEs. The design is not tailored for a specific set of applications and they do not perform analysis on the interactions between the memory and processing systems, leaving the modeling of the memory system as future work.

Plasticine, a spatial processor optimized for the acceleration of parallel patterns is presented in \cite{prabhakar2017plasticine}. Their memory system is composed of Pattern Memory Units (PMUs) which are connected through a network to Pattern Compute Units (PCUs). Although it allows some degree of configuration, Plasticine is not meant to be optimized around specific applications. The input application needs to be written in a language exposing its parallel patterns - Delite Hardware Definition Language (DHDL) - and then it is mapped on the Plasticine architecture. Hence, the number of memory units (PMUs) and processing units (PCUs), and their interconnections are not optimized around specific applications.

In \cite{budiu2004spatial}, a framework to generate Application Specific Hardware (ASH) from a C application is presented. The final architecture it produces is asynchronous, and operation dependencies are handled using a token-based mechanism which is implemented in hardware. The memory system of the architecture consists of a monolithic memory. To handle concurrent memory requests the design uses a hierarchy of busses and arbiters, which creates a bottleneck. This means that their memory system is overwhelmed because it is not tailored for the PEs it uses.

Spatially distributed PEs with a dedicated configuration register allow to configure the PEs to one of the operating modes \cite{streamproc2019} at compile time. Few PEs are connected back-to-back, forming systolic arrays which are then interconnected using an on-chip interconnect. Thus, the processor architecture is quite general-purpose, i.e, the interconnect allows a PE array to be connected to any another PE array. However, there is no automated design flow to efficiently map algorithms to the processor architecture.

An interesting approach is Catena\cite{cerqueira2020catena}, an ultra-low-power spatial processor with a distributed architecture, where multiple techniques - \textit{clock gating}, \textit{power gating} and \textit{voltage boosting} - are applied in a fine-grained way to optimize energy efficiency. These techniques can be used to explore the power/latency tradeoff of specific applications. However, the impact of the memory system on the performance of the design is not modeled and the memory system is not co-designed with the spatial processor, potentially resulting in an inefficient utilization of the hardware resources; moreover, Catena lacks high-level language support.

In summary, a comparison of \frameworkname~against existing work is presented in Table \ref{tab:rw}.

\begin{table}[!ht]
 \resizebox{0.5\textwidth}{!}{%
\footnotesize
    \begin{tabular}{|l|l|l|l|l|l|}
      \hline
  Framework & Type    & Application & Memory & Architectural& High Level \\
           & (see \ref{sec:bg})    & Optimized & Co-Design &DSE & Language \\ \hline
\frameworkname         & Dist. Control       & Yes                   & Yes              & Yes               & Yes, C              \\ \hline
%            & Control       &                    &               &                &              \\ \hline
\cite{parashar2014efficient}               & Dist. Control       & No                    & No               & No                & No                  \\ \hline
%            & Control       &                    &                &                 &                   \\ \hline
\cite{prabhakar2017plasticine}               & Dist. Control       & No                    & No               & No                & Yes, DHDL         \\ \hline
            %&        &                     &                &                 & DHDL           \\ \hline
\cite{streamproc2019}               & Dist. Control       & No                    & No               & No                & No           \\ \hline
%            & Control       &                     &                &                 &            \\ \hline
\cite{budiu2004spatial}               & Logic & Yes                   & No               & No                & Yes, C \\
            & Grained &                    &                &                 &  \\ \hline
 \cite{cerqueira2020catena}              & Dist. Control  & Yes                   & No               & Yes                & No \\ \hline
%            & Control  &                    &                &                 &  \\ \hline
\end{tabular}
}
\caption{Comparison with related work.}
\label{tab:rw}
\end{table}
