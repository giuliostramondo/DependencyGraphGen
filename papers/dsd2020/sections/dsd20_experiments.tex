\begin{figure}[ht]
\centering
%\begin{subfigure}{.33\textwidth}
%  \centering
%  \includegraphics[width=\textwidth]{graphs/energy_plot_single_sram_v3.pdf}
%  \caption{5x5 MM}
%  \label{fig:single_sram}
%\end{subfigure}%
%\begin{subfigure}{.33\textwidth}
%  \centering
  \includegraphics[width=0.3\textwidth]{graphs/EnergyParetoMatrixVec10_v3.pdf}
%  \caption{MV 10x10}
%\end{subfigure}
%\begin{subfigure}{.33\textwidth}
%  \centering
%  \includegraphics[width=\textwidth]{graphs/EnergyParetoMatrixMul10_v3.pdf}
%  \caption{MM 10x10}
%  \label{fig:sram_vs_mram_pareto_mul}
%\end{subfigure}
    \caption{\small Each point represents one \frameworkname~spatial processor. Different shapes identify different input configurations. Note that only include the Pareto-optimal designs are included.}
\label{fig:sram_vs_mram_pareto_vec}
\end{figure}
\section{Case Study}
\label{sec:case_studies}
In this section, we demonstrate the capabilities of \frameworkname~using one case study. To do so, we analyze the architectures generated by \frameworkname~and the energy consumption and latency (or execution time) of each design.
We selected one representative application: matrix-vector (MV) multiplication with matrix sizes $10\times10$. We used the TSMC 28nm target technology library for generating the database containing the area usage and energy consumption of the different building blocks, as required by our framework.
We generated multiple input \textit{Configuration Parameters} to let \frameworkname~explore the parameter space, and compute the latency, area usage, and energy consumption of the architectures. Each generated architecture has a known latency imposed in each iteration of the DSE (Section~\ref{ssec:dse}), which we use to compute its static energy consumption. Moreover, after applying the Modified Interval Partitioning algorithm, the instructions performed by each PE are known and this information is used to compute the dynamic energy consumption of an architecture.

The case study - Section \ref{ssec:case_study2} - compares the use of MRAM - modeled according to~\cite{8310393} - and SRAM for L2M (both in 28nm) for the two applications, thus showing the impact of choosing different memory technologies in the L2M.

%\vspace{-1mm}
%\subsection{Single configuration DSE}
\label{ssec:exp_single}
%\vspace{-1mm}
%The goal of this case-study is to illustrate the ability of \frameworkname~to generate, given a single configuration, architectures with different energy consumption. We selected a configuration that uses SRAM in both levels. L2M is clocked at 350MHz, while L1M and the spatial processor are clocked at 1GHz. Figure 7a shows the energy consumption of 30 different pareto-optimal spatial processor architectures, with different latency and energy consumption. We make two observations: (1) the latency and energy consumption of each design range between the min and max latency, as given by the \textbf{MostPar} and \textbf{MostSeq} architectures, and (2) as expected, faster designs result in higher energy consumption, due to their larger numbers of PEs.

%The \textbf{MostPar} - starting point of our DSE - is the fastest architecture completing the computation in 412 clock cycles of the spatial processor and it consumes $11.1^3$ mW-ns. The \textbf{MostSeq} - ending point of the DSE - is the slowest, completing in 436 clock cycles and consuming $6^3$ mW-ns. Between these two extreme design points, the DSE generates intermediate architectures with various energy-latency tradeoffs.

\vspace{-1mm}
\subsection{MRAM vs SRAM Level 2 Memory}
\label{ssec:case_study2}
\vspace{-1mm}

In this case study we compare the energy efficiency of two alternative technologies to implement L2M: MRAM and SRAM.
The comparison is performed the representative applications - MV - with $10\times10$ matrices (see Fig~\ref{fig:sram_vs_mram_pareto_vec}). In the graph, each point is relative to a hardware architecture generated by \frameworkname; moreover shapes identify different input configurations. Specifically, we compare a total of 18 configurations: 2 L2M technologies, MRAM and SRAM, clocked at 350MHz, and 9 different clock frequencies (400MHz - 1GHz, in steps of 200) for the processor and L1M ensemble.

We can identify two clusters: LL-HE (low-latency, high-energy) and HL-LE (high-latency, low-energy). Each cluster belongs to one memory technology: LL-HE contains all SRAM designs, while HL-LE contains all MRAM designs.
For the considered application (Fig~\ref{fig:sram_vs_mram_pareto_vec}) the fastest architecture - using SRAM memory - has a latency of 1375ns and consumes over $1\times10^5$Joules. The most energy efficient SRAM architecture has instead a latency of 1525ns and consumes under $0.3\times10^5$Joules, thus being 3x more energy efficient than the fastest, with a latency increase of only 10\%. The most energy efficient architecture using MRAM technology has instead a latency of 2210ns and consumes $0.24\times10^5$Joules, hence having 45\% higher latency than the best SRAM counterpart, with 25\% lower energy consumption.


%\subsection{Different Matrix Dimensions}
%\label{ssec:case_study3}
%In this case study we compare three different matrix sizes for MV - $5\times5$, $10\times10$ and $15\times15$, using the same configurations used in~\ref{ssec:case_study2}, to evaluate how the energy consumption of an L2M MRAM scales with respect to an L2M SRAM. Figure~\ref{fig:sram_vs_mram_pareto_vec_sizes} shows the Pareto-optimal architectures generated from each input application. The increase in the matrix size is reflected by an increase in latency: all MV-$5\times5$ application-specific processors have latency below 1000ns, the MV-$10\times10$ have latency between 1250ns and 2500ns, and the latency of all MV-$15\times15$ is beyond 2500ns.
%However, the increased number of operations results instead in wider trade-offs possibilities. Thus, the normalized latency gap between the most energy efficient SRAM and MRAM, decreases with the matrix size, from 82\% for the $5\times5$, to 42\% for the 10x10 and even 32\% for the $15\times15$. The reduction in energy consumption between the same pair of results is instead 20\% for the $5\times5$ and $10\times10$, while for the $15\times15$ drops to 16\%. Therefore, as the size of the matrix grows, the benefits in energy consumption diminish when using MRAM technology in the L2M. This behavior caused by the increased number of write operations that have high energy impact when the MRAM technology is used.



%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.33\textwidth]{graphs/EnergyParetoPlotMultipleSizeMAtrixVec_v3.pdf}
%    \caption{\small Energy Pareto optimal architectures generated by \frameworkname ~for different sizes of Matrix Vector multiplication 5x5 - with latency ranging from 0 to 1000,10x10 - having latency between 1000ns and 2500ns , and 15x15- with latency above 2500ns. Each point corresponds to an architecture generated by the framework.}
%\label{fig:sram_vs_mram_pareto_vec_sizes}
%\end{figure}
