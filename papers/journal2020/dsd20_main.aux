\relax 
\citation{parashar2014efficient,prabhakar2017plasticine,budiu2004spatial,streamproc2019,cerqueira2020catena,7284058,8686088}
\citation{williams2009roofline,dayarathna2015data,oh2009analytical}
\citation{mem2016}
\citation{synopsystool,tensilica,codasiptool}
\citation{Meloni2012,EusseSAMOS2014,Jozwiak2013,Karuri2009}
\citation{4798259,7092595,6271803,Mittal13f}
\citation{parashar2014efficient}
\citation{parashar2014efficient}
\citation{swanson2007wavescalar}
\citation{parashar2014efficient,prabhakar2017plasticine,cerqueira2020catena}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Difference between state-of-the-art design flow typically used for traditional application-specific processors and the proposed $\mu $-Genie\nobreakspace  {}design flow for spatial processors.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background}{1}}
\newlabel{sec:bg}{{II}{1}}
\citation{parashar2014efficient}
\citation{parashar2014efficient}
\citation{llvm}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Spatial Architectures classification \cite  {parashar2014efficient}.\relax }}{2}}
\newlabel{fig:spatial_class}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}The $\mu $-Genie\nobreakspace  {}framework}{2}}
\newlabel{sec:framework}{{III}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Model of Execution}{2}}
\newlabel{ssec:system_under_analysis}{{\unhbox \voidb@x \hbox {III-A}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}The L2 Memory Model}{2}}
\newlabel{ssec:layer2_model}{{\unhbox \voidb@x \hbox {III-B}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}$\mu $-Genie: Inputs}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Application}{2}}
\newlabel{ssec:app}{{\unhbox \voidb@x \hbox {IV-A}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Configuration Parameters}{2}}
\newlabel{ssec:conf_param}{{\unhbox \voidb@x \hbox {IV-B}}{2}}
\citation{isoda1983global}
\citation{hwang1991formal}
\citation{greedyIntervalPartitioning}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  $\mu $-Genie\nobreakspace  {}Framework.\relax }}{3}}
\newlabel{fig:framework}{{3}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  The system under analysis. \relax }}{3}}
\newlabel{fig:system}{{4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}$\mu $-Genie: Analysis}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}L2 Memory Read and Write Modeling}{3}}
\newlabel{ssec:l2_read_model}{{\unhbox \voidb@x \hbox {V-A}}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Definition of symbols used in the equations\relax }}{3}}
\newlabel{table:equation}{{I}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Data Dependency Analysis}{3}}
\newlabel{ssec:dda}{{\unhbox \voidb@x \hbox {V-B}}{3}}
\citation{hwang1991formal}
\citation{greedyIntervalPartitioning}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  A Data Dependency Graph: inverse triangles represent input data, obtained from the \textit  {load} instructions; ovals describe operations on data; the triangle at the bottom represents the result, derived from a \textit  {store} instruction. Highlighted, a chain of associative operations before being optimized by the \textit  {DDA} module (\unhbox \voidb@x \hbox {V-B}\hbox {}).\relax }}{4}}
\newlabel{fig:ddg}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}PE allocation with Modified Interval Partitioning}{4}}
\newlabel{ssec:modified_interval_partitioning}{{\unhbox \voidb@x \hbox {V-C}}{4}}
\newlabel{lst:modified_interval_partitioning}{{1}{4}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}\relax \fontsize  {9}{10pt}\selectfont  Modified Interval Partitioning (MIP) Algorithm}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Most Parallel and Most Sequential Architectures}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}$\mu $-Genie: Design Space Exploration (DSE)}{5}}
\newlabel{ssec:dse}{{VI}{5}}
\newlabel{lst:dse}{{2}{5}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}\relax \fontsize  {9}{10pt}\selectfont  Design Space Exploration}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Architecture Tradeoffs}{5}}
\newlabel{ssec:arch_tradeoffs}{{\unhbox \voidb@x \hbox {VI-A}}{5}}
\newlabel{fig:max_par_arch}{{6a}{5}}
\newlabel{sub@fig:max_par_arch}{{a}{5}}
\newlabel{fig:inter_arch}{{6b}{5}}
\newlabel{sub@fig:inter_arch}{{b}{5}}
\newlabel{fig:most_seq_arch}{{6c}{5}}
\newlabel{sub@fig:most_seq_arch}{{c}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Example of architectures generated from a matrix vector multiply application of size 5x5. The MostPar (a), an intermediate architecture (b) and the MostSeq (c).\relax }}{5}}
\newlabel{fig:tradeoffs}{{6}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Multi-Configuration Design Space Exploration}{5}}
\newlabel{ssec:multiconf_dse}{{\unhbox \voidb@x \hbox {VI-B}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Architectural Template}{5}}
\newlabel{sec:arch_template}{{VII}{5}}
\citation{8310393}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Functional Unit template. PE1-PE4 represent "parent" PEs that generate input data. IM is an internal Instruction Memory,where the PE stores the operations to be performed. RFs are internal Register Files, which store reuse data and inputs to be used in the future. OP is the hardware unit actually performing the PE operation.\relax }}{6}}
\newlabel{fig:FU_templ}{{7}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Case Studies}{6}}
\newlabel{sec:case_studies}{{VIII}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VIII-A}}Single configuration DSE}{6}}
\newlabel{ssec:exp_single}{{\unhbox \voidb@x \hbox {VIII-A}}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VIII-B}}MRAM vs SRAM Level 2 Memory}{6}}
\newlabel{ssec:case_study2}{{\unhbox \voidb@x \hbox {VIII-B}}{6}}
\citation{parashar2014efficient}
\citation{prabhakar2017plasticine}
\citation{budiu2004spatial}
\newlabel{fig:single_sram}{{8a}{7}}
\newlabel{sub@fig:single_sram}{{a}{7}}
\newlabel{fig:sram_vs_mram_pareto_vec}{{8b}{7}}
\newlabel{sub@fig:sram_vs_mram_pareto_vec}{{b}{7}}
\newlabel{fig:sram_vs_mram_pareto_mul}{{8c}{7}}
\newlabel{sub@fig:sram_vs_mram_pareto_mul}{{c}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Each point represents one $\mu $-Genie\nobreakspace  {}spatial processor. Different shapes (in 8b\hbox {} and\nobreakspace  {}8c\hbox {}) identify different input configurations. 8a\hbox {} shows the architecture's Energy over Latency in clock cycles generated from a single configuration of a matrix vector multiplication of size $5\times 5$. Note that (a) presents all designs, while (b) and (c) only include the Pareto-optimal designs.\relax }}{7}}
\newlabel{fig:case_studies_1}{{8}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VIII-C}}Different Matrix Dimensions}{7}}
\newlabel{ssec:case_study3}{{\unhbox \voidb@x \hbox {VIII-C}}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Related Work}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \relax \fontsize  {9}{10pt}\selectfont  Energy Pareto optimal architectures generated by $\mu $-Genie\nobreakspace  {}for different sizes of Matrix Vector multiplication 5x5 - with latency ranging from 0 to 1000,10x10 - having latency between 1000ns and 2500ns , and 15x15- with latency above 2500ns. Each point corresponds to an architecture generated by the framework.\relax }}{7}}
\newlabel{fig:sram_vs_mram_pareto_vec_sizes}{{9}{7}}
\citation{streamproc2019}
\citation{cerqueira2020catena}
\citation{parashar2014efficient}
\citation{prabhakar2017plasticine}
\citation{streamproc2019}
\citation{budiu2004spatial}
\citation{cerqueira2020catena}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Comparison with related work.\relax }}{8}}
\newlabel{tab:rw}{{II}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {X}Conclusion and Future Work}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {XI}Method}{8}}
\newlabel{ch:method}{{XI}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {XII}Efficiency metrics}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {XIII}Merging method for architectures}{8}}
\newlabel{method:method}{{XIII}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIII-A}}Isolating the \textit  {mcs}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIII-B}}Mapping leftovers}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XIII-C}}Completing the graph}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {XIV}Design-space exploration for efficiency}{9}}
\newlabel{method:dse}{{XIV}{9}}
\citation{konc2007improved}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces A view of our full merging flow. We use $\mu $-Genieto generate sets of architectures from the program descriptions. After merging these sets, we use a DSE process to find the merged architectures that are efficient.\relax }}{10}}
\newlabel{fig:full_flow}{{10}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {XV}Implementation}{10}}
\newlabel{method:implementation}{{XV}{10}}
\newlabel{fig:running_example:a}{{11a}{10}}
\newlabel{sub@fig:running_example:a}{{a}{10}}
\newlabel{fig:running_example:b}{{11b}{10}}
\newlabel{sub@fig:running_example:b}{{b}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The input architectures of our running example. Architecture 1 has an extra \texttt  {add\_1} node inserted compared to architecture 2.\relax }}{10}}
\newlabel{fig:running_example}{{11}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Pseudocode of the compatibility graph construction from two input graphs, where \texttt  {v1} and \texttt  {u1} are vertices in graph 1 and \texttt  {v2} and \texttt  {u2} are vertices in graph 2.\relax }}{10}}
\newlabel{fig:cgconstruction}{{12}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The disconnected \textit  {mcs} of the running example.\relax }}{10}}
\newlabel{fig:runningmcs}{{13}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Pseudocode of the mapping procedure for the leftovers.\relax }}{11}}
\newlabel{fig:mapping}{{14}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The \textit  {mcs} of the running example extended with the mapped leftovers.\relax }}{11}}
\newlabel{fig:runningextended}{{15}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The final result of the running example.\relax }}{11}}
\newlabel{fig:runningfinal}{{16}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {XVI}Empirical Evaluation}{11}}
\newlabel{ch:results}{{XVI}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {XVII}Architecture merging validation}{11}}
\newlabel{fig:multimcs:a}{{17a}{12}}
\newlabel{sub@fig:multimcs:a}{{a}{12}}
\newlabel{fig:multimcs:b}{{17b}{12}}
\newlabel{sub@fig:multimcs:b}{{b}{12}}
\newlabel{fig:multimcs:c}{{17c}{12}}
\newlabel{sub@fig:multimcs:c}{{c}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces \texttt  {add\_1} and \texttt  {add\_4} are not part of the \textit  {mcs} due to being connected to \texttt  {load\_0} and \texttt  {load\_5} respectively. \texttt  {load\_2} and \texttt  {add\_2} map to \texttt  {load\_5} and \texttt  {add\_5} respectively, forming one part of the \textit  {mcs}. The cluster of two loads and one add forms the other part of the \textit  {mcs}.\relax }}{12}}
\newlabel{fig:multimcs}{{17}{12}}
\newlabel{fig:leftovers:a}{{18a}{12}}
\newlabel{sub@fig:leftovers:a}{{a}{12}}
\newlabel{fig:leftovers:b}{{18b}{12}}
\newlabel{sub@fig:leftovers:b}{{b}{12}}
\newlabel{fig:leftovers:c}{{18c}{12}}
\newlabel{sub@fig:leftovers:c}{{c}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces \texttt  {mul\_1} and \texttt  {mul\_2} cannot be part of the \textit  {mcs} due to \texttt  {mul\_2} connecting to \texttt  {load\_2}. Both \texttt  {mul\_1} and \texttt  {mul\_2} have two connections to the add in the \textit  {mcs}, and are thus merged together.\relax }}{12}}
\newlabel{fig:leftovers}{{18}{12}}
\newlabel{fig:multiple:a}{{19a}{13}}
\newlabel{sub@fig:multiple:a}{{a}{13}}
\newlabel{fig:multiple:b}{{19b}{13}}
\newlabel{sub@fig:multiple:b}{{b}{13}}
\newlabel{fig:multiple:c}{{19c}{13}}
\newlabel{sub@fig:multiple:c}{{c}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces All three load nodes and the store node are identical, and thus part of the \textit  {mcs}, though disconnected. We see that all four unique nodes are added to the result as leftovers, and all appropriate edges are added.\relax }}{13}}
\newlabel{fig:multiple}{{19}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {XVIII}Method evaluation}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Input program source code.\relax }}{13}}
\newlabel{fig:source}{{20}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces List of metrics that we evaluate for our merged architectures.\relax }}{14}}
\newlabel{tab:evaluationmetrics}{{III}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XVIII-A}}Findings}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XVIII-B}}Relative merging efficiency}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Area reduction for each pair of input architectures. Highlighted with blue borders are the architectures that are Pareto-optimal for latency, area, and energy.\relax }}{14}}
\newlabel{fig:plot_heatmap_area_reduction}{{21}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Energy increase for each pair of input architectures. Highlighted with blue borders are the architectures that are Pareto-optimal for latency, area, and energy.\relax }}{15}}
\newlabel{fig:plot_heatmap_energy_increase}{{22}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Comparison of the area reduction between the Pareto set of architectures and all architectures.\relax }}{15}}
\newlabel{fig:pareto_comparison}{{23}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {XVIII-C}}Merged architecture trade-offs}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Resulting area for each pair of architectures. Area measured in $1e^5$.\relax }}{16}}
\newlabel{fig:plot_heatmap_area}{{24}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {XIX}Programming the PEs}{16}}
\newlabel{chap:design}{{XIX}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {XX}Requirements}{16}}
\newlabel{sec:requirements}{{XX}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Resulting energy for each pair of architectures. Energy measured in $1e^4$.\relax }}{16}}
\newlabel{fig:plot_heatmap_energy}{{25}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Area Pareto plot for the architectures resulting from our exploration.\relax }}{17}}
\newlabel{fig:plot_pareto_latency_area}{{26}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces The input types which function as an abstraction to control the multiplexers, as well as which register in the RF data, coming from the input ports or as a result from a previously executed $Op$ instruction, is written to.\relax }}{17}}
\newlabel{tab:inputs}{{IV}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces All instructions in the Architecture Template Assembly we specified.\relax }}{17}}
\newlabel{tab:insts}{{V}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Energy Pareto plot for the architectures resulting from our exploration.\relax }}{17}}
\newlabel{fig:plot_pareto_latency_energy}{{27}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {XXI}Architecture Template Assembly specification}{17}}
\newlabel{sec:assembly}{{XXI}{17}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces Relation of the fields in the ATA instructions to the fields in the FU instructions.\relax }}{18}}
\newlabel{tab:ATA-MC}{{VI}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {VII}{\ignorespaces Values for the multiplexers and their correspondig cbOut ports depending the value of one of the `input' fields of the $Op$ instruction.\relax }}{18}}
\newlabel{tab:mux}{{VII}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {XXII}Methodology overview}{18}}
\newlabel{sec:overview}{{XXII}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {VIII}{\ignorespaces Values for REG0, REG1 and cbOut depending on the value of `input' of the $Store$ instruction.\relax }}{18}}
\newlabel{tab:reg}{{VIII}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Overview of the methodology (read from top to bottom).\relax }}{18}}
\newlabel{fig:framework}{{28}{18}}
\bibstyle{IEEEtran}
\bibdata{dsd20_biblio}
\bibcite{parashar2014efficient}{1}
\bibcite{prabhakar2017plasticine}{2}
\bibcite{budiu2004spatial}{3}
\bibcite{streamproc2019}{4}
\bibcite{cerqueira2020catena}{5}
\bibcite{7284058}{6}
\bibcite{8686088}{7}
\bibcite{williams2009roofline}{8}
\@writefile{toc}{\contentsline {section}{References}{19}}
\bibcite{dayarathna2015data}{9}
\bibcite{oh2009analytical}{10}
\bibcite{mem2016}{11}
\bibcite{synopsystool}{12}
\bibcite{tensilica}{13}
\bibcite{codasiptool}{14}
\bibcite{Meloni2012}{15}
\bibcite{EusseSAMOS2014}{16}
\bibcite{Jozwiak2013}{17}
\bibcite{Karuri2009}{18}
\bibcite{4798259}{19}
\bibcite{7092595}{20}
\bibcite{6271803}{21}
\bibcite{Mittal13f}{22}
\bibcite{swanson2007wavescalar}{23}
\bibcite{llvm}{24}
\bibcite{isoda1983global}{25}
\bibcite{hwang1991formal}{26}
\bibcite{greedyIntervalPartitioning}{27}
\bibcite{8310393}{28}
\bibcite{konc2007improved}{29}
